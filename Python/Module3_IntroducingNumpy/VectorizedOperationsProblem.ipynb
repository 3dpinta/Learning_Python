{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Function Problem\n",
    "Let's say we are trying to determine how accurate a function is at classifying objects into various classes. We can determine this accuracy through an accuracy function. In this case, there are N different classes, and we have classified M points. Our original function has already provided us the probabilities of these M points being classified into each of the N classes, stored in a NumPy array with the shape (M, N). In addition, we have another array with a shape of (M,). This array stores the correct classification of each point M, with each class defined as a value within [0, N). Our accuracy function would take both arrays as input, and return what percentage of the time our function is correct.\n",
    "\n",
    "Our function should behave as follows:\n",
    "```python\n",
    "# example behavior\n",
    ">>> accuracy(preds, labels)\n",
    "0.945\n",
    ">>> preds.shape\n",
    "(100, 10)\n",
    ">>> labels.shape\n",
    "(100,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution (without vectorization):\n",
    "We would need to start by finding what label each point would have. We know each row in the predictions array stores the probabilities for each class for a particular data point. Thus, the highest probability in that row would be the true classification of that point. We can use a function known as `numpy.argmax` to get the index of the highest probability, which would tell us the predicted classification for that data point.\n",
    "\n",
    "```python\n",
    "# where each predicted classification is stored.\n",
    "preds = np.zeros(truth.shape)\n",
    "# loop through each row, or \"point\", and stores the predicted classification\n",
    "for i, point_probs in enumerate(predictions):\n",
    "    # since point_probs is now a 1D array, this should just return the index of the highest \n",
    "    # probability, or the most probable class each point could be defined as.\n",
    "    preds[i] = np.argmax(point_probs)\n",
    "```\n",
    "\n",
    "Next, we need to get whether each predicted classification matches the true classification. We can loop through each point and see whether the two classes are equal and store this information in a boolean array.\n",
    "\n",
    "```python\n",
    "# stores whether each predicted classification matches the true classification\n",
    "truth_vals = np.zeros(truth.shape)\n",
    "# loops through each predicted classification and stores whether it is equal to the true classification\n",
    "for i in range(len(preds)):\n",
    "    truth_vals[i] = (preds[i] == truth[i])\n",
    "```\n",
    "\n",
    "Boolean arrays are special because when we pass that array through the function `np.mean`, each boolean value gets reassigned an integer value. Each `True` value is equal to 1, and each `False` value is equal to 0. This means we can obtain the frequency of the predicted classification being correct, and divide it by the total number of points classified. This would equal the percentage of times the predictions were correct, or in other words the \"accuracy\" of the function that obtained these predictions.\n",
    "\n",
    "We can formally write this out into the following function:\n",
    "\n",
    "```python\n",
    "def accuracy(predictions, truth):\n",
    "    \"\"\"\n",
    "    Returns the mean classification accuracy for a batch of predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : numpy.ndarray, shape=(M, D)\n",
    "        The scores for D classes, for a batch of M data points\n",
    "    truth : numpy.ndarray, shape=(M,)\n",
    "        The true labels for each datum in the batch: each label is an\n",
    "        integer in [0, D)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    preds = np.zeros(truth.shape)\n",
    "    for i, point_probs in enumerate(predictions):\n",
    "        preds[i] = np.argmax(point_probs)\n",
    "    truth_vals = np.zeros(truth.shape)\n",
    "    for i in range(len(preds)):\n",
    "        truth_vals[i] = (preds[i] == truth[i])\n",
    "    return np.mean(truth_vals)\n",
    "```\n",
    "Horray! We have a working accuracy function! However, this function is inefficient and involves many for loops. Let's see if we can fix this using vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal solution (with vectorization):\n",
    "We can start making this function smaller by looking at our usage of `np.argmax`. This function is, in fact, a vectorized sequential function that NumPy provides. Recognizing this, we could get the same prediction array without a for loop by using the axis parameter. In this case, since we want to return the of each row and compare the column values, we want to get the along axis 1. We thus able to rewrite obtaining our predicted classifications as follows:\n",
    "\n",
    "```python\n",
    "np.argmax(predictions, axis=1)\n",
    "```\n",
    "\n",
    "Next, we can use NumPy's vectorized == function to get an array of when the predicted labels match the true labels. This can then be put into `np.mean` like before. Combining this into a function, we obtain the following:\n",
    "\n",
    "```python\n",
    "def accuracy(predictions, truth):\n",
    "    \"\"\"\n",
    "    Returns the mean classification accuracy for a batch of predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : numpy.ndarray, shape=(M, D)\n",
    "        The scores for D classes, for a batch of M data points\n",
    "    truth : numpy.ndarray, shape=(M,)\n",
    "        The true labels for each datum in the batch: each label is an\n",
    "        integer in [0, D)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    return np.mean(np.argmax(predictions, axis=1) == truth)\n",
    "```\n",
    "\n",
    "Not only is this cleaner to look at, but it uses NumPy's built-in vectorization to make it faster than using for-loops to loop through these arrays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
